{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yPrK4q7jtDt"
      },
      "outputs": [],
      "source": [
        "# Justas Baniulis;LSP: 2015956; Klases: Parachute, Mushroom, Pizza; Modelis: VGG19"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "P45ZhBuKlyg_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU ir modelio atsisiuntimas\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "weights = models.VGG19_Weights.IMAGENET1K_V1\n",
        "model = models.vgg19(weights=weights).to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKWTLMtKerYL",
        "outputId": "e25be1cb-d64c-49e1-e1b4-9be6ce3e5b2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openimages"
      ],
      "metadata": {
        "id": "Ont2fxsiOhit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbe2143-d105-4172-a256-9be6374dc319"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openimages\n",
            "  Downloading openimages-0.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting cvdata\n",
            "  Downloading cvdata-0.0.3-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from openimages) (4.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openimages) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from openimages) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from openimages) (2.25.1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.81-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.81\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/8a/c2/066ee3e9f3ff0145ee07bf48c6a3efa81cafdaf5a6b00218ad640252b334/botocore-1.29.81-py3-none-any.whl\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading botocore-1.29.81-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from cvdata->openimages) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from cvdata->openimages) (8.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from cvdata->openimages) (4.6.0.66)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openimages) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->openimages) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->openimages) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->openimages) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->openimages) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->openimages) (4.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->openimages) (1.15.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, cvdata, openimages\n",
            "Successfully installed boto3-1.26.81 botocore-1.29.81 cvdata-0.0.3 jmespath-1.0.1 openimages-0.0.1 s3transfer-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openimages.download import download_dataset\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "\n",
        "# atsisiusti duomenis i direktorija\n",
        "data_dir = \"data\"\n",
        "\n",
        "# pravalymui direktorijos\n",
        "#shutil.rmtree(data_dir)\n",
        "\n",
        "# Pasirenkam klases ir ju kieki\n",
        "chosen_classes = [('Parachute', 360), ('Mushroom', 360), ('Pizza', 360)]\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "for name, count in chosen_classes:\n",
        "  print(name)\n",
        "  download_dataset(data_dir, class_labels=[name], limit=count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCqSyqodHoFy",
        "outputId": "4da9bb60-330c-4cba-ac14-0eb8556e5023"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parachute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 360/360 [00:05<00:00, 68.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mushroom\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 325/325 [00:05<00:00, 64.59it/s]\n",
            "100%|██████████| 32/32 [00:00<00:00, 40.86it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00,  7.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pizza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 360/360 [00:05<00:00, 66.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# atsikratom greyscaled nuotrauku kiekvienos klases\n",
        "for c_temp in chosen_classes:\n",
        "  directory = data_dir + \"/{}/images\".format(c_temp[0].lower())\n",
        "  for filename in os.listdir(directory):\n",
        "    filepath = os.path.join(directory, filename)\n",
        "    with Image.open(filepath) as img:\n",
        "      if img.mode == \"L\":\n",
        "        # If the image is greyscale, delete it\n",
        "        os.remove(filepath)\n",
        "        print(f\"Deleted {filepath} because it is greyscale.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W8tKVIW8UE9",
        "outputId": "1a6218e2-b1cf-414e-f4e9-16babf297498"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted data/parachute/images/52c6153ed8637197.jpg because it is greyscale.\n",
            "Deleted data/parachute/images/4f9f1a3167a175e4.jpg because it is greyscale.\n",
            "Deleted data/parachute/images/5312e8dabd0f5346.jpg because it is greyscale.\n",
            "Deleted data/parachute/images/0c7c13bc5d7b5e16.jpg because it is greyscale.\n",
            "Deleted data/parachute/images/11225278874edc90.jpg because it is greyscale.\n",
            "Deleted data/parachute/images/2435c841e5ab4c0a.jpg because it is greyscale.\n",
            "Deleted data/pizza/images/39c8b88543a2e207.jpg because it is greyscale.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Transformacijos\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset nuotraukai\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images_dir):\n",
        "        # direktorija ir transformacijos dataset'ui\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # failu path'ai. (failas, klase)\n",
        "        self.class1_files = [(item, chosen_classes[0][0]) for item in glob.glob(self.images_dir + \"/{}/images/*.jpg\".format(chosen_classes[0][0].lower()))]\n",
        "        self.class2_files = [(item, chosen_classes[1][0]) for item in glob.glob(self.images_dir + \"/{}/images/*.jpg\".format(chosen_classes[1][0].lower()))]\n",
        "        self.class3_files = [(item, chosen_classes[2][0]) for item in glob.glob(self.images_dir + \"/{}/images/*.jpg\".format(chosen_classes[2][0].lower()))]\n",
        "\n",
        "        # visi failai\n",
        "        self.files = self.class1_files + self.class2_files + self.class3_files\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.files))\n",
        "    \n",
        "    # grazinsim faila ir jo klase\n",
        "    def __getitem__(self, i):\n",
        "        file_i = self.files[i]\n",
        "        \n",
        "        im = Image.open(file_i[0])\n",
        "\n",
        "        if self.transform:\n",
        "          try:\n",
        "            image = self.transform(im)\n",
        "          except RuntimeError:\n",
        "            raise Exception(f\"Faulty image: '{file_i[0]}'\")\n",
        "            \n",
        "        y = file_i[1]\n",
        "        return image, y\n"
      ],
      "metadata": {
        "id": "PKzbuyr0mIiW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(calculations):\n",
        "  \n",
        "  TP = calculations['TP']\n",
        "  TN = calculations['TN']\n",
        "  FP = calculations['FP']\n",
        "  FN = calculations['FN']\n",
        "\n",
        "  metrics = {}\n",
        "  metrics['accuracy'] = (TP + TN) / (TP + FP + TN + FN)\n",
        "  metrics['recall'] = TP / (TP + FN)\n",
        "  metrics['precision'] = TP / (TP + FP)\n",
        "  metrics['F1'] = 2 * (metrics['precision'] * metrics['recall']) / (metrics['precision'] + metrics['recall'])\n",
        "\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "GS353SLgM_4n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rinkinys, darbininkai, slenkstine reiksme\n",
        "batch_n = 30\n",
        "workers_n = 4\n",
        "threshold = 0.05\n",
        "\n",
        "# duomenu aibe ir paruosejas\n",
        "dataSet = ImageDataset(data_dir)\n",
        "dataLoader = DataLoader(dataSet, batch_size=batch_n, shuffle=True)\n",
        "\n",
        "# pasiruosiam sarasa su klasem (id, vardas, {TP, TN, FP, FN})\n",
        "classes_calc = []\n",
        "for class_i in chosen_classes:\n",
        "  calc = {'TP':0, 'TN':0, 'FP':0, 'FN':0}\n",
        "  classes_calc.append((weights.meta[\"categories\"].index(class_i[0].lower()),class_i[0], calc))\n",
        "\n",
        "# dedam rinkinius i modeli ir skaiciuojam TP, TN, FP, FN\n",
        "for batch, class_names in dataLoader:\n",
        "  batch = batch.to(device)\n",
        "  predictions = model(batch).softmax(0)\n",
        "\n",
        "  #iteruojam per rinkini spejimu\n",
        "  for i in range(0, len(predictions)):\n",
        "    prediction = predictions[i]\n",
        "\n",
        "    #iteruojam per pasirinktas klases\n",
        "    for c in classes_calc:\n",
        "\n",
        "      # jeigu perzerngiam slenksti, tai esam positive\n",
        "      if prediction[c[0]] >= threshold:\n",
        "\n",
        "        if(c[1] == class_names[i]):\n",
        "          c[2]['TP'] += 1\n",
        "\n",
        "        # type 1 error\n",
        "        else:\n",
        "          c[2]['FP'] += 1\n",
        "\n",
        "      # jeigu NEperzerngiam slenksti, tai esam negative    \n",
        "      else:\n",
        "\n",
        "        # type 2 error\n",
        "        if(c[1] == class_names[i]):\n",
        "          c[2]['FN'] += 1\n",
        "\n",
        "        else:\n",
        "          c[2]['TN'] += 1\n"
      ],
      "metadata": {
        "id": "mr_4suTCMD94"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rezultatai:\n",
        "TP_t= 0\n",
        "TN_t= 0\n",
        "FP_t= 0\n",
        "FN_t = 0\n",
        "\n",
        "for c in classes_calc:\n",
        "  print(c[1])\n",
        "  print(calculate_metrics(c[2]))\n",
        "  print(\"   \")\n",
        "\n",
        "  TP_t += c[2]['TP']\n",
        "  TN_t += c[2]['TN']\n",
        "  FP_t += c[2]['FP']\n",
        "  FN_t += c[2]['FN']\n",
        "\n",
        "all_metrics = calculate_metrics({'TP': TP_t, 'TN': TN_t, 'FP': FP_t, 'FN': FN_t})\n",
        "print(\"All\")\n",
        "print(all_metrics)"
      ],
      "metadata": {
        "id": "OMbFxHTDpR1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913d5b41-3eb0-4c9b-cd04-e375f874a501"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parachute\n",
            "{'accuracy': 0.7194780987884436, 'recall': 0.1497175141242938, 'precision': 1.0, 'F1': 0.2604422604422605}\n",
            "   \n",
            "Mushroom\n",
            "{'accuracy': 0.7399813606710158, 'recall': 0.225, 'precision': 1.0, 'F1': 0.36734693877551017}\n",
            "   \n",
            "Pizza\n",
            "{'accuracy': 0.7287977632805219, 'recall': 0.1894150417827298, 'precision': 1.0, 'F1': 0.3185011709601873}\n",
            "   \n",
            "All\n",
            "{'accuracy': 0.7294190742466604, 'recall': 0.18825722273998136, 'precision': 1.0, 'F1': 0.31686274509803924}\n"
          ]
        }
      ]
    }
  ]
}