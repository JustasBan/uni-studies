{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AaJV7Am8eVn"
      },
      "outputs": [],
      "source": [
        "#Justas Baniulis 2015956 cat car pizza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Cw_TclwmZ-4f",
        "outputId": "c399d85f-99d2-4832-d5f9-1f82bfc6356f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m   )\n\u001b[0;32m--> 177\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    102\u001b[0m     ):\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install oidv6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgibbeGjEJtk",
        "outputId": "51aa7c4d-5e0e-48b3-d16d-5f8159d753c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting oidv6\n",
            "  Downloading oidv6-1.0.5-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.9/dist-packages (from oidv6) (1.22.4)\n",
            "Requirement already satisfied: progressbar2>=3.51.3 in /usr/local/lib/python3.9/dist-packages (from oidv6) (4.2.0)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.9/dist-packages (from oidv6) (1.4.4)\n",
            "Collecting awscli>=1.18.69\n",
            "  Downloading awscli-1.27.104-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.9/dist-packages (from oidv6) (4.7.0.72)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from oidv6) (2.27.1)\n",
            "Collecting botocore==1.29.104\n",
            "  Downloading botocore-1.29.104-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML<5.5,>=3.10\n",
            "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.9/dist-packages (from awscli>=1.18.69->oidv6) (0.16)\n",
            "Collecting rsa<4.8,>=3.1.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting colorama<0.4.5,>=0.2.5\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.104->awscli>=1.18.69->oidv6) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.104->awscli>=1.18.69->oidv6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.4->oidv6) (2022.7.1)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from progressbar2>=3.51.3->oidv6) (3.5.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->oidv6) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->oidv6) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->oidv6) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.29.104->awscli>=1.18.69->oidv6) (1.16.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.9/dist-packages (from rsa<4.8,>=3.1.2->awscli>=1.18.69->oidv6) (0.4.8)\n",
            "Installing collected packages: rsa, PyYAML, jmespath, colorama, botocore, s3transfer, awscli, oidv6\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed PyYAML-5.4.1 awscli-1.27.104 botocore-1.29.104 colorama-0.4.4 jmespath-1.0.1 oidv6-1.0.5 rsa-4.7.2 s3transfer-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "#viska atsisiunciam ir nukeliam i drive kad siustis nereiktu kas kart\n",
        "\n",
        "!oidv6 downloader --classes cat car pizza --type_data train --no_labels --limit 800 --dest_dir OIDv6/train\n",
        "!oidv6 downloader --classes cat car pizza --type_data validation --no_labels --limit 150 --dest_dir OIDv6/validation\n",
        "!oidv6 downloader --classes cat car pizza --type_data test --no_labels --limit 150 --dest_dir OIDv6/validation\n",
        "\n",
        "target_folder = \"/content/drive/MyDrive/OIDv6\"\n",
        "download_folder = \"/content/OIDv6\"\n",
        "\n",
        "shutil.copytree(download_folder, target_folder)"
      ],
      "metadata": {
        "id": "jNmFHY7iEg8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "folder_test = '/content/drive/MyDrive/OIDv6/test'\n",
        "folder_train = '/content/drive/MyDrive/OIDv6/train'\n",
        "folder_validation = '/content/drive/MyDrive/OIDv6/validation'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WreUL-xU3njk",
        "outputId": "1c0932b1-f1b6-43db-a6b4-759738f7e672"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# modelis\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        \n",
        "        # pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 14 * 14, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 3)\n",
        "\n",
        "        # randomly set output features to 0\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # downsample the output of the convolutional layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "\n",
        "        # reshape\n",
        "        x = x.view(-1, 128 * 14 * 14)\n",
        "\n",
        "        # dropout of fully connected layers\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Net()\n"
      ],
      "metadata": {
        "id": "iFDU_H2E5hoa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentacijos & transformacijos\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.ColorJitter(brightness=0.4, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomGrayscale(p=0.1),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "XXjHC19cLJyM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tranformuojam ir susirenkam nuotraukas\n",
        "train_data = datasets.ImageFolder(folder_train, transform=data_transforms['train'])\n",
        "validation_data = datasets.ImageFolder(folder_validation, transform=data_transforms['validation'])\n",
        "test_data = datasets.ImageFolder(folder_test, transform=data_transforms['test'])\n",
        "\n",
        "# loadinam\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(validation_data, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "myrS7WuG2qo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "\n",
        "# gpu\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "\n",
        "# loss func & optimizer (to update the model parameters)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "#scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "num_epochs = 25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # training\n",
        "\n",
        "    model.train()\n",
        "    train_loss_values = np.array([], dtype = np.float32)\n",
        "    train_corrects = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # i gpu duodam batch\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # gradientai nulinami\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # grazinam\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # argmax suskaiciuojam\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # sumuojam teisingus spejimus ir loss\n",
        "        train_corrects += torch.sum(preds == labels.data)\n",
        "        train_loss_values = np.append(train_loss_values, loss.cpu().detach().numpy())\n",
        "\n",
        "        # atnaujinam parametrus\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #gradientai nulinami\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    #scheduler.step()\n",
        "\n",
        "    #progreso stebejimas\n",
        "    epoch_loss = np.mean(train_loss_values)\n",
        "    epoch_acc = train_corrects.double() / len(train_data)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Trn Loss: {epoch_loss:.4f}, trn Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # validuojame (nebus dropouts)\n",
        "    model.eval()\n",
        "    val_loss_values = np.array([], dtype = np.float32)\n",
        "    val_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            # i gpu duodam batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # grazinam ir per argmax skaiciuojam\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # sumuojam teisingus spejimus ir loss\n",
        "            val_loss_values = np.append(val_loss_values, loss.cpu().detach().numpy())\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = np.mean(val_loss_values)\n",
        "        epoch_acc = val_corrects.double() / len(validation_data)\n",
        "        print(f\"Val Loss: {epoch_loss:.4f}, Val Acc: {epoch_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr1f8m7eMJ9r",
        "outputId": "9cff6198-76eb-478a-fc9e-e947eab8f664"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n",
            "Epoch 1/25\n",
            "Trn Loss: 0.9430, trn Acc: 0.5329\n",
            "Val Loss: 0.9976, Val Acc: 0.4579\n",
            "Epoch 2/25\n",
            "Trn Loss: 0.8144, trn Acc: 0.6604\n",
            "Val Loss: 0.6294, Val Acc: 0.7816\n",
            "Epoch 3/25\n",
            "Trn Loss: 0.7482, trn Acc: 0.7075\n",
            "Val Loss: 0.6579, Val Acc: 0.7184\n",
            "Epoch 4/25\n",
            "Trn Loss: 0.6976, trn Acc: 0.7358\n",
            "Val Loss: 0.4683, Val Acc: 0.8368\n",
            "Epoch 5/25\n",
            "Trn Loss: 0.6558, trn Acc: 0.7458\n",
            "Val Loss: 0.5346, Val Acc: 0.7816\n",
            "Epoch 6/25\n",
            "Trn Loss: 0.6355, trn Acc: 0.7571\n",
            "Val Loss: 0.4402, Val Acc: 0.8368\n",
            "Epoch 7/25\n",
            "Trn Loss: 0.5968, trn Acc: 0.7646\n",
            "Val Loss: 0.3442, Val Acc: 0.8789\n",
            "Epoch 8/25\n",
            "Trn Loss: 0.5996, trn Acc: 0.7721\n",
            "Val Loss: 0.4079, Val Acc: 0.8500\n",
            "Epoch 9/25\n",
            "Trn Loss: 0.5497, trn Acc: 0.7892\n",
            "Val Loss: 0.3597, Val Acc: 0.8579\n",
            "Epoch 10/25\n",
            "Trn Loss: 0.5569, trn Acc: 0.7888\n",
            "Val Loss: 0.3905, Val Acc: 0.8579\n",
            "Epoch 11/25\n",
            "Trn Loss: 0.5354, trn Acc: 0.8013\n",
            "Val Loss: 0.3684, Val Acc: 0.8842\n",
            "Epoch 12/25\n",
            "Trn Loss: 0.4883, trn Acc: 0.8175\n",
            "Val Loss: 0.3753, Val Acc: 0.8474\n",
            "Epoch 13/25\n",
            "Trn Loss: 0.5012, trn Acc: 0.8121\n",
            "Val Loss: 0.3890, Val Acc: 0.8474\n",
            "Epoch 14/25\n",
            "Trn Loss: 0.5014, trn Acc: 0.8117\n",
            "Val Loss: 0.4089, Val Acc: 0.8237\n",
            "Epoch 15/25\n",
            "Trn Loss: 0.4688, trn Acc: 0.8263\n",
            "Val Loss: 0.3697, Val Acc: 0.8526\n",
            "Epoch 16/25\n",
            "Trn Loss: 0.4471, trn Acc: 0.8371\n",
            "Val Loss: 0.3088, Val Acc: 0.8947\n",
            "Epoch 17/25\n",
            "Trn Loss: 0.4646, trn Acc: 0.8288\n",
            "Val Loss: 0.2615, Val Acc: 0.9079\n",
            "Epoch 18/25\n",
            "Trn Loss: 0.4408, trn Acc: 0.8413\n",
            "Val Loss: 0.3321, Val Acc: 0.8921\n",
            "Epoch 19/25\n",
            "Trn Loss: 0.4495, trn Acc: 0.8292\n",
            "Val Loss: 0.2962, Val Acc: 0.9053\n",
            "Epoch 20/25\n",
            "Trn Loss: 0.4183, trn Acc: 0.8442\n",
            "Val Loss: 0.3249, Val Acc: 0.8711\n",
            "Epoch 21/25\n",
            "Trn Loss: 0.4092, trn Acc: 0.8508\n",
            "Val Loss: 0.3322, Val Acc: 0.8947\n",
            "Epoch 22/25\n",
            "Trn Loss: 0.3921, trn Acc: 0.8525\n",
            "Val Loss: 0.2823, Val Acc: 0.9105\n",
            "Epoch 23/25\n",
            "Trn Loss: 0.3848, trn Acc: 0.8654\n",
            "Val Loss: 0.2438, Val Acc: 0.9289\n",
            "Epoch 24/25\n",
            "Trn Loss: 0.4185, trn Acc: 0.8367\n",
            "Val Loss: 0.2283, Val Acc: 0.9053\n",
            "Epoch 25/25\n",
            "Trn Loss: 0.3815, trn Acc: 0.8542\n",
            "Val Loss: 0.2364, Val Acc: 0.9237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    # dedam i modeli\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    # gaunam spejimus\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "    # kaupiam spejima ir tikrove\n",
        "    y_true.extend(labels.cpu().numpy())\n",
        "    y_pred.extend(preds.cpu().numpy())"
      ],
      "metadata": {
        "id": "NrZdZIePTQLX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# klasiu vardai\n",
        "data_dir = '/content/drive/MyDrive/OIDv6/validation'\n",
        "dataset = datasets.ImageFolder(data_dir)\n",
        "\n",
        "class_names = dataset.classes\n",
        "\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "RPByB6jjo7Zy",
        "outputId": "22df58ab-a872-4792-f86d-0b28000fb781"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fed3de223322>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# klasiu vardai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/OIDv6/validation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/OIDv6/validation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "\n",
        "# Metrikos\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, columns=class_names, index=class_names)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_df)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score:: {f1_score:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4XxWMQSsREb",
        "outputId": "c006a4b4-bc1d-4089-d331-f781d41ae2cc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "       car  cat  pizza\n",
            "car    139    5      6\n",
            "cat      7  130     13\n",
            "pizza    2    2    146\n",
            "Accuracy: 0.9222\n",
            "Precision: 0.9243\n",
            "Recall: 0.9222\n",
            "F1 Score:: 0.9219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modelio issisaugojimas\n",
        "torch.save(model.state_dict(), \"my_model2.pth\")"
      ],
      "metadata": {
        "id": "WtnRCN6Z5s3C"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modelio uzsikrovimas\n",
        "model = Net()\n",
        "model_weights = torch.load('/content/my_model.pth', map_location=torch.device('cpu'))\n",
        "model.load_state_dict(model_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecUliQ4Oy_lw",
        "outputId": "c30bc84f-abab-4cb7-da65-d5666b9293e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-cors pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTGmz364K_63",
        "outputId": "efa9f218-7fe4-408e-bc0b-a8083fd5098d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.9/dist-packages (from flask-cors) (1.16.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.9/dist-packages (from flask-cors) (2.2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyngrok) (6.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.9->flask-cors) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.9->flask-cors) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.9->flask-cors) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.9->flask-cors) (2.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.9->flask-cors) (6.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6.0->Flask>=0.9->flask-cors) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask-cors) (2.1.2)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19790 sha256=cb791ef45a7a92c6d5c9a67ccf3acfa4328d37ec3b71fa59c1dce40c4a4921d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/89/59/49d4249e00957e94813ac136a335d10ed2e09a856c5096f95c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok, flask-cors\n",
            "Successfully installed flask-cors-3.0.10 pyngrok-5.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REST api\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import io\n",
        "from PIL import Image\n",
        "import base64\n",
        "from flask_cors import CORS\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app, resources={r\"*\": {\"origins\": \"*\"}})\n",
        "model = model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "@app.route(\"/test\", methods=[\"GET\"])\n",
        "def test():\n",
        "    return \"This is a test endpoint.\"\n",
        "\n",
        "def preprocess_image(image_file):\n",
        "    image = Image.open(image_file)\n",
        "    transformed_image = data_transforms['test'](image)\n",
        "    return transformed_image.unsqueeze(0)\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    print(\"Received request data:\", request.files, request.data)\n",
        "\n",
        "    try:\n",
        "        # Get the image from the request\n",
        "        file = request.files.get(\"image\")\n",
        "        if not file:\n",
        "            return jsonify({\"error\": \"No image provided\"}), 400\n",
        "\n",
        "        # Preprocess the image\n",
        "        processed_image = preprocess_image(file)\n",
        "        processed_image = processed_image.to('cpu')\n",
        "\n",
        "        # Make a prediction using the model\n",
        "        with torch.no_grad():\n",
        "            output = model(processed_image)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            prediction = predicted.item()\n",
        "\n",
        "        # Prepare the response\n",
        "        response = {\n",
        "            \"prediction\": class_names[prediction]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(\"Error processing request:\", e)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "    return jsonify(response)\n",
        "\n",
        "# Set up pyngrok\n",
        "ngrok_tunnel = ngrok.connect(5000)\n",
        "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "\n",
        "# Run the Flask app\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViQWEwCD6AwM",
        "outputId": "d7d017bf-b418-4500-c03f-4abdeca5add8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: http://e16a-34-74-108-45.ngrok.io\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Apr/2023 20:02:26] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received request data: ImmutableMultiDict([('image', <FileStorage: '338681621_796162218084476_2355268349714035306_n.jpg' ('image/jpeg')>)]) b''\n"
          ]
        }
      ]
    }
  ]
}